[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fiscal Policy Shocks, Aggregate Economy and Stock Prices: Evidence from the Australian Economy",
    "section": "",
    "text": "Abstract. This is a research proposal, the project is about measuring fiscal policy effects using Bayesian Structural Vector Autoregression (SVAR) in Australian Economy. Impulse responses of stock prices and macroeconomic aggregates will be investigated.\nKeywords. fiscal policy shock, SVAR, tax shocks, stock price, impulse response function"
  },
  {
    "objectID": "index.html#baseline-model",
    "href": "index.html#baseline-model",
    "title": "Fiscal Policy Shocks, Aggregate Economy and Stock Prices: Evidence from the Australian Economy",
    "section": "Baseline Model",
    "text": "Baseline Model\nRewrite the reduced form equation in matrix:\n\\[\\begin{gather}\nY = XA + E \\\\\n\\\\ E|X \\sim MN_{T \\times N}(0_{T \\times N},\\Sigma,I_T)\n\\end{gather}\\]\nThe Likelihood function would be: \\[\\begin{gather}\nL(A,\\Sigma|Y,X) \\propto det(\\Sigma)^{-\\frac{T}{2}} exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(Y-XA)'(Y-XA) \\right] \\right\\} \\\\\n\\\\ \\propto det(\\Sigma)^{-\\frac{T}{2}} exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(A-\\hat{A})'X'X(A-\\hat{A}) \\right] \\right\\} exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}(Y-X \\hat{A})'(Y-X \\hat{A}) \\right] \\right\\} \\\\\n\\end{gather}\\]\nFrom Maximum Likelihood Estimation, \\[\\begin{gather}\n\\hat{A} = (X'X)^{-1}X'Y \\\\\n\\\\ \\hat{\\Sigma} = \\frac{1}{T} (Y-X \\hat{A})'(Y-X \\hat{A})\n\\end{gather}\\]\nIn the basic model, we have prior as: \\[\\begin{gather}\np(A,\\Sigma) = p(A|\\Sigma) p(\\Sigma) \\\\\n\\\\ A|\\Sigma \\sim MN_{K \\times N} (\\underline{A}, \\Sigma , \\underline{V}) \\\\\n\\\\ \\Sigma \\sim IW_{N}(\\underline{S},\\underline{\\nu})\n\\end{gather}\\]\nParameters are as follows: \\[\\begin{gather}\n\\underline{A} = [0_{N \\times 1} \\quad I_N \\quad 0_{N \\times (p-1)N}]' \\\\\n\\\\ Var[vec(A)] = \\Sigma \\otimes  \\underline{V} \\\\\n\\\\ \\underline{V} = \\text{diag}([\\kappa_2 \\quad \\kappa_1 (p^{-2} \\otimes \\imath_N)]) \\\\\n\\\\ p = [1,2,...p], \\qquad \\imath_N = [1,...,1]\n\\end{gather}\\]\nThe full conditional posterior is: \\[\\begin{gather}\np(A,\\Sigma|Y,X) = p(A|Y,X,\\Sigma)p(\\Sigma|Y,X) \\\\\n\\\\ p(A|Y,X,\\Sigma) = MN_{K \\times N}(\\bar{A}, \\Sigma, \\bar{V}) \\\\\n\\\\ p(\\Sigma | Y, X) = IW_N(\\bar{S},\\bar{\\nu})\n\\end{gather}\\]\nDerive the full conditional posterior: \\[\\begin{gather}\nP(A,\\Sigma|Y,X) \\propto L(A,\\Sigma|Y,X)p(A,\\Sigma) \\\\\n\\\\ \\propto L(A,\\Sigma|Y,X)p(A|\\Sigma)p(\\Sigma) \\\\\n\\\\ det(\\Sigma)^{-\\frac{T}{2}} \\times exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(A-\\hat{A})' X'X (A-\\hat{A})\\right] \\right\\} \\\\\n\\\\ \\times exp\\left\\{-\\frac{1}{2}tr \\left[ \\Sigma^{-1}(Y-X\\hat{A})'(Y-X\\hat{A}) \\right] \\right\\} \\\\\n\\\\ \\times det(\\Sigma)^{-\\frac{N+K+\\underline{\\nu}+1}{2}} \\\\\n\\\\ \\times exp\\left\\{-\\frac{1}{2}tr \\left[ \\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A}) \\right] \\right\\} \\\\\n\\\\ \\times exp \\left\\{ -\\frac{1}{2} tr \\left[ \\Sigma^{-1} \\underline{S} \\right] \\right\\}\n\\end{gather}\\]\n\\[\\begin{gather}\np(A,\\Sigma|Y,X) \\propto det{(\\Sigma)}^{-\\frac{T+N+K+ \\underline{\\nu}\n+1}{2}} \\times exp \\left\\{-\\frac{1}{2}tr \\left[ \\Sigma^{-1} \\left[(A-\\hat{A})^{'}X'X(A-\\hat{A})+(A-\\underline{A})^{'} \\underline{V}^{-1}(A-\\underline{A}) + (Y-X\\hat{A})^{'}(Y-X\\hat{A})+\\underline{S}  \\right]\\right] \\right\\}\\\\\n\\\\ \\propto det{(\\Sigma)}^{-\\frac{T+N+K+ \\underline{\\nu}\n+1}{2}} \\times exp\\left\\{ -\\frac{1}{2} tr \\left[ \\Sigma^{-1} \\left[ (A-\\bar{A})^{'} \\bar{V}^{-1} (A-\\bar{A})+\\underline{S} +Y^{'}Y + \\underline{A}^{'} \\underline{V}^{-1}\\underline{A} -\\bar{A}^{'} \\bar{V}^{-1}\\bar{A}\\right]\\right]\\right\\}\n\\end{gather}\\]\nwhere we have posterior distribution parameters:\n\\[\\begin{gather}\n\\bar{V} = (X^{'}X+ \\underline{V}^{-1})^{-1} \\\\\n\\\\ \\bar{A} = \\bar{V}(X^{'}Y+\\underline{V}^{-1} \\underline{A}) \\\\\n\\\\ \\bar{\\nu} = T + \\underline{\\nu} \\\\\n\\\\ \\bar{S} = \\underline{S} + Y^{'}Y +  \\underline{A}^{'}\\underline{V}^{-1}\\underline{A} - \\bar{A}^{'}\\bar{V}^{-1}\\bar{A}\n\\end{gather}\\]\nFrom above derivation, we can compute functions to calculate parameters:\n\n\n\n\nGetPosterior.parameters <- function (X,Y,prior.parameters) {\n  \n  A.prior <- prior.parameters$A.prior\n  V.prior <- prior.parameters$V.prior\n  S.prior <- prior.parameters$S.prior\n  nu.prior <- prior.parameters$nu.prior\n  \n  V.bar.inv <- t(X)%*%X + diag(1/diag(V.prior))\n  V.bar <- solve(V.bar.inv)\n  A.bar <- V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)\n  nu.bar <- nrow(Y) + nu.prior\n  S.bar <- S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar\n  \n  return (list(V.bar = V.bar,\n               A.bar = A.bar,\n               nu.bar = nu.bar,\n               S.bar = S.bar))\n}\n\nThen posterior distributions of \\(A\\) and \\(\\Sigma\\) can be drawn:\n\nDrawPosterior <- function (N,S,p,posterior.parameters){\n  \n  K = 1+N*p\n  \n  A.bar  <- posterior.parameters$A.bar\n  V.bar  <- posterior.parameters$V.bar\n  S.bar  <- posterior.parameters$S.bar\n  nu.bar <- posterior.parameters$nu.bar\n  \n  Sigma.posterior   <- rWishart(S, df=nu.bar, Sigma=solve(S.bar))  \n  Sigma.posterior   <- apply(Sigma.posterior,3,solve)            \n  Sigma.posterior   <- array(Sigma.posterior,c(N,N,S))   \n  A.posterior       <- array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S)) \n  B.posterior       <- array(NA,c(N,N,S))\n  \n  L                 <- t(chol(V.bar)) \n  B1.tilde.s        <- array(NA,c(N,K,S))\n  \n  for (s in 1:S){\n    cholSigma.s      <- chol(Sigma.posterior[,,s])\n    # B.posterior[,,s]= t(cholSigma.s)\n    B.posterior[,,s] <- solve(t(cholSigma.s)) \n    A.posterior[,,s] <- A.bar + L%*%A.posterior[,,s]%*%cholSigma.s \n    B1.tilde.s[,,s]  <- B.posterior[,,s]%*%t(A.posterior[,,s])\n  }\n\n  return(list(A.posterior     = A.posterior,\n              B.posterior     = B.posterior,\n              B1.tilde.s      = B1.tilde.s,\n              Sigma.posterior = Sigma.posterior)\n         )\n}\n\nAfter the posterior draws, we apply sign restrictions to identify the model. For any set of sign restrictions, given a parameter point \\(B_{+},B_{0}\\) that satisfies such restrictions, there always exists an orthogonal matrix Q, arbitrarily close to an identity such that \\(QB_{+},QB_{0}\\) satisfy the sign restrictions.\nThe Algorithm from Fry and Pagan (2011) is implemented to transfer SF parameters \\((\\tilde{B_+},\\tilde{B_0})\\) to parameters \\((B_{+},B_{0})\\) such the restrictions of interest holds.\n\nImposeSignRestriction <- function (restrictions,N,p,posterior.draws){\n  \n  A.posterior <- posterior.draws$A.posterior\n  Sigma.posterior <- posterior.draws$Sigma.posterior\n  B.posterior <- posterior.draws$B.posterior\n  B1.tilde.s <- posterior.draws$B1.tilde.s\n  \n  S <- dim(A.posterior)[3]\n  \n  R1 <- diag(restrictions)\n  B0.draws      = array(NA,c(N,N,S))\n  B1.draws      = array(NA,c(N,(1+N*p),S))\n  i.vec = c()\n\n  for (s in 1:S){\n    A             = A.posterior[,,s]\n    Sigma         = Sigma.posterior[,,s]\n    B0.tilde      = B.posterior[,,s]\n    B1.tilde      = B1.tilde.s[,,s]\n    \n    i=1\n    sign.restrictions.do.not.hold = TRUE \n    while (sign.restrictions.do.not.hold){\n    X           = matrix(rnorm(N*N),N,N)         \n    QR          = qr(X, tol = 1e-10)\n    Q           = qr.Q(QR,complete=TRUE)\n    R           = qr.R(QR,complete=TRUE)\n    Q           = t(Q %*% diag(sign(diag(R))))\n    B0          = Q%*%B0.tilde                    \n    B1          = Q%*%B1.tilde                   \n    B0.inv      = solve(B0)      \n    check       = prod(R1 %*% B0.inv %*% diag(N)[,2] >= 0)\n    if (check){sign.restrictions.do.not.hold=FALSE}\n    i=i+1 \n    }\n    i.vec = c(i.vec,i) \n    B0.draws[,,s] = B0\n    B1.draws[,,s] = B1\n  }\n  return (list(B0.draws = B0.draws,\n               B1.draws = B1.draws,\n               i = i.vec))\n}\n\n\n\n\n\n\n\nTable 5 and Table 6 show the matrix of \\(A\\) and \\(\\Sigma\\), suggesting the basic model estimation using artificial data of 1 lag and constant term is showing zero posterior mean of the autoregressive and covariance matrices are close to an identity matrix and the posterior mean of the constant term is close to zeros too.\n\n\n\n\nTable 5: Basic Model - A\n\n\n0.0245\n0.0588\n\n\n0.9839\n0.0022\n\n\n-0.0030\n1.0569\n\n\n\n\n\n\n\n\n\n\nTable 6: Basic Model - Sigma\n\n\n1.0238\n0.0000\n\n\n0.0000\n1.0235"
  },
  {
    "objectID": "index.html#stochastic-volatility-heteroskedasticity",
    "href": "index.html#stochastic-volatility-heteroskedasticity",
    "title": "Fiscal Policy Shocks, Aggregate Economy and Stock Prices: Evidence from the Australian Economy",
    "section": "Stochastic Volatility Heteroskedasticity",
    "text": "Stochastic Volatility Heteroskedasticity\nConsidering potential existence of heteroskedasticity in the variables I used, Stochastic Volatility (SV) models can be estimated, for which the specification would be: \\[\\begin{gather}\nY = XA + E \\\\\n\\\\ E|X \\sim MN_{T \\times N}(0_{T \\times N},\\Sigma,\\text{diag}(\\sigma^2))\n\\end{gather}\\] where \\(\\sigma^2=(\\sigma^2_1,...,\\sigma^2_T)^{'}\\), which follows a Stochastic Volatility process.\nThen we have the likelihood function as: \\[\\begin{gather}\nL(A,\\Sigma|Y,X,\\sigma^2) \\propto det(\\text{diag}(\\sigma^2))^{-\\frac{N}{2}} det(\\Sigma)^{-\\frac{T}{2}} exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(Y-XA)'\\text{diag}(\\sigma^2)^{-1}(Y-XA) \\right] \\right\\} \\\\\n\\end{gather}\\]\nThe full conditional posterior of \\((A,\\Sigma)\\) would follow a \\(MNIW(\\bar{A},\\bar{V},\\bar{S},\\bar{\\nu})\\) distribution. \\[\\begin{gather}\np(A,\\Sigma|X,Y,\\sigma^2) \\propto L(A,\\Sigma|Y,X,\\sigma^2) \\times  p(A|\\Sigma,\\sigma^2) \\times p(\\Sigma)\n\\end{gather}\\] with parameters: \\[\\begin{gather}\n\\bar{V} = (X'\\text{diag}(\\sigma^2)^{-1}X+\\underline{V}^{-1})^{-1} \\\\\n\\\\ \\bar{A} = \\bar{V}(X'\\text{diag}(\\sigma^2)^{-1}Y+\\underline{V}^{-1}\\underline{A}) \\\\\n\\\\ \\bar{S} = \\underline{S} + Y'\\text{diag}(\\sigma^2)^{-1}Y + \\underline{A}^{'}\\underline{V}^{-1}\\underline{A} - \\bar{A}^{'}\\bar{V}^{-1}\\bar{A} \\\\\n\\\\ \\bar{\\nu}= T + \\underline{\\nu}\n\\end{gather}\\]\nGibbs Sampler can be conducted to get the posterior draws of the extended model, for which we can,\nInitialize \\(\\sigma^2\\) at \\({\\sigma^2}^{(0)}\\).\nAt each iteration s:\n\nDraw \\((A,\\Sigma)^{(s)} \\sim p(A,\\Sigma| X,Y,{\\sigma^2}^{(s-1)})\\)\nDraw \\({\\sigma^2}^{(s)} \\sim p(\\sigma^2|Y,X,A^{(s)},\\Sigma^{(s)})\\)\n\nRepeat 1 and 2 for \\((S_1 + S_2)\\) times.\nDiscard the first \\(S_1\\).\nStep 2 is conducted based on the following chunk of code:\n\nSVcommon.Gibbs.iteration <- function(aux, priors){\n  # A single iteration of the Gibbs sampler for the SV component\n\n  # aux is a list containing:\n  #   Y         - a TxN matrix\n  #   X         - a TxK matrix\n  #   H         - a Tx1 matrix                 \n  #   h0        - a scalar\n  #   sigma.v2  - a scalar\n  #   s         - a Tx1 matrix\n  #   A         - a KxN matrix\n  #   Sigma     - an NxN matrix\n  #   sigma2    - a Tx1 matrix\n  \n  # priors is a list containing:\n  #   h0.v      - a positive scalar\n  #   h0.m      - a scalar\n  #   sigmav.s  - a positive scalar\n  #   sigmav.nu - a positive scalar\n  #   HH        - a TxT matrix\n\n  T             = dim(aux$Y)[1]\n  N             = dim(aux$Y)[2]\n  alpha.st      = c(1.92677,1.34744,0.73504,0.02266,0-0.85173,-1.97278,-3.46788,-5.55246,-8.68384,-14.65000)\n  sigma.st      = c(0.11265,0.17788,0.26768,0.40611,0.62699,0.98583,1.57469,2.54498,4.16591,7.33342)\n  pi.st         = c(0.00609,0.04775,0.13057,0.20674,0.22715,0.18842,0.12047,0.05591,0.01575,0.00115)\n\n  Lambda        = solve(chol(aux$Sigma))\n  Z             = rowSums( ( aux$Y - aux$X %*% aux$A ) %*% Lambda ) / sqrt(N)\n  Y.tilde       = as.vector(log((Z + 0.0000001)^2))\n  Ytilde.alpha  = as.matrix(Y.tilde - alpha.st[as.vector(aux$s)])\n\n  # sampling initial condition\n  V.h0.bar      = 1/((1 / priors$h0.v) + (1 / aux$sigma.v2))\n  m.h0.bar      = V.h0.bar*((priors$h0.m / priors$h0.v) + (aux$H[1] / aux$sigma.v2))\n  h0.draw       = rnorm(1, mean = m.h0.bar, sd = sqrt(V.h0.bar))\n  aux$h0        = h0.draw    \n\n  # sampling sigma.v2\n  sigma.v2.s    = priors$sigmav.s + sum(c(aux$H[1] - aux$h0, diff(aux$H))^2)\n  sigma.v2.draw = sigma.v2.s / rchisq(1, priors$sigmav.nu + T)\n  aux$sigma.v2  = sigma.v2.draw    \n\n  # sampling auxiliary states\n  Pr.tmp        = simplify2array(lapply(1:10,function(x){\n    dnorm(Y.tilde, mean = as.vector(aux$H + alpha.st[x]), sd = sqrt(sigma.st[x]), log = TRUE) + log(pi.st[x])\n  }))\n  Pr            = t(apply(Pr.tmp, 1, function(x){exp(x - max(x)) / sum(exp(x - max(x)))}))\n  s.cum         = t(apply(Pr, 1, cumsum))\n  r             = matrix(rep(runif(T), 10), ncol = 10)\n  ss            = apply(s.cum < r, 1, sum) + 1\n  aux$s         = as.matrix(ss)       \n\n\n  # sampling log-volatilities using functions for tridiagonal precision matrix\n  Sigma.s.inv   = diag(1 / sigma.st[as.vector(aux$s)])\n  D.inv         = Sigma.s.inv + (1 / aux$sigma.v2) * priors$HH\n  b             = as.matrix(Ytilde.alpha / sigma.st[as.vector(aux$s)] + (aux$h0/aux$sigma.v2)*diag(T)[,1])\n  lead.diag     = diag(D.inv)\n  sub.diag      = mgcv::sdiag(D.inv, -1)\n  D.chol        = mgcv::trichol(ld = lead.diag, sd = sub.diag)\n  D.L           = diag(D.chol$ld)\n  mgcv::sdiag(D.L,-1) = D.chol$sd\n  x             = as.matrix(rnorm(T))\n  a             = forwardsolve(D.L, b)\n  draw          = backsolve(t(D.L), a + x)\n  aux$H         = as.matrix(draw)         \n  aux$sigma2    = as.matrix(exp(draw))     \n\n  return(aux)\n}\n\n\nDrawPosterior.sv <- function (Y,X,prior.parameters,S1,S2){\n  \n  N <- ncol(Y)\n  K <- ncol(X)\n  T <- nrow(Y)\n  \n  A.prior  <- prior.parameters$A.prior\n  V.prior  <- prior.parameters$V.prior\n  S.prior  <- prior.parameters$S.prior\n  nu.prior <- prior.parameters$nu.prior\n\n  A.posterior     <- array(NA,c(K,N,(S1+S2)))\n  Sigma.posterior <- array(NA,c(N,N,(S1+S2))) \n  H.posterior     <- array(NA,c(nrow(Y),(S1+S2+1)))  \n  B.posterior     <- array(NA,c(N,N,(S1+S2)))\n  B1.tilde.s      <- array(NA,c(N,K,(S1+S2)))\n  \n  # Initialize h^{0}, which is  T by 1 matrix \n  H.posterior[,1]       <- matrix(1,T,1) \n  \n  nu.bar                <- nrow(Y) + nu.prior\n  \n  HH                    <-  2*diag(T)\n  mgcv::sdiag(HH,-1)    <-  -1\n  mgcv::sdiag(HH,1)     <-  -1\n  \n  priors = list(HH       = HH,\n                h0.m     = 0,\n                h0.v     = 1,\n                sigmav.s = 1,\n                sigmav.nu= 1\n              )\n  \n  for (s in 1:(S1+S2)){\n    # STEP 1: draw (A Sigma).s from MNIW(A.bar,V.bar,S.bar,nu.bar)\n    # setting up parameters \n    \n    V.bar.inv       <- t(X)%*%diag(1/H.posterior[,s])%*%X + diag(1/diag(V.prior))\n    V.bar           <- solve(V.bar.inv)\n    A.bar           <- V.bar%*%(t(X)%*%diag(1/H.posterior[,s])%*%Y + diag(1/diag(V.prior))%*%A.prior)\n    S.bar           <- S.prior+t(Y)%*%diag(1/H.posterior[,s])%*%Y+t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar\n    \n    draw.sigma.inv  <- solve(rWishart(1, df=nu.bar, Sigma=solve(S.bar))[,,1])\n    Sigma.posterior[,,s] = draw.sigma.inv\n      \n      # start drawing \n    cholSigma.s      <- chol(Sigma.posterior[,,s])\n    A.posterior[,,s] <- matrix(MASS::mvrnorm(1,as.vector(A.bar),Sigma.posterior[,,s]%x%V.bar),ncol=N)      \n    \n    L                <- t(chol(V.bar))\n    # B.posterior[,,s] <- t(chol(Sigma.posterior[,,s]))\n    B.posterior[,,s] <- solve(t(chol(Sigma.posterior[,,s])))  \n    B1.tilde.s[,,s]  <- B.posterior[,,s]%*%t(A.posterior[,,s])\n    \n    # STEP 2: draw H from SVcommon.Gibbs.iteration\n    if (s == 1){ # initializing input arguments \n        aux = list( \n              Y             = Y,\n              X             = X,\n              H             = matrix(1,T,1),\n              h0            = 0,\n              sigma.v2      = 1,\n              s             = matrix(1,T,1),\n              Sigma         = Sigma.posterior[,,s],\n              A             = A.posterior[,,s],\n              sigma2        = matrix(1,T,1)\n              )\n    }else{ # updating input arguments  \n      aux = list(\n                Y           = Y,\n                X           = X,\n                H           = tmp$H,\n                h0          = tmp$h0,\n                sigma.v2    = tmp$sigma.v2,\n                s           = tmp$s,\n                Sigma       = Sigma.posterior[,,s],\n                A           = A.posterior[,,s],\n                sigma2      = tmp$sigma2\n              )\n    }\n\n    # H                     <- diag(T)\n    # sdiag(H,-1)           <- -1     \n    tmp                     <- SVcommon.Gibbs.iteration(aux,priors)\n    H.posterior[,s+1]      <- as.matrix(tmp$sigma2)\n  }\n  \n  return(list(Sigma.posterior = Sigma.posterior[,,(S1+1):(S1+S2)],\n              A.posterior     = A.posterior[,,(S1+1):(S1+S2)],\n              B1.tilde.s      = B1.tilde.s[,,(S1+1):(S1+S2)],\n              B.posterior     = B.posterior[,,(S1+1):(S1+S2)],\n              H.sv            = H.posterior[,(S1+2):(S1+S2+1)]))\n  }\n\n\n\n\nFigure 6 provides a time series plot of posterior draws mean of \\(\\sigma^2\\) at each time spot. From where we can observe the \\(\\sigma^2\\) oscillating around 2400.\n\n\n\n\n\nFigure 6: Posterior Draw Mean of Stochastic Volatility\n\n\n\n\nFigure 7 plots the S2 draws of Gibbs Sampler of the Stochastic Volatility model, and it shown to be stationary for A and \\(\\Sigma\\) when \\(S_1=5000, S_2=45000\\).From where, we can observe the mean of \\(A_{21},A_{32}\\) varying around value of 1, \\(\\Sigma_{21},\\Sigma_{22}\\) oscillating around 0.0018-0.0019. Under the existence of stochastic volatility, it does not make sense to check whether the posterior draw of \\(\\Sigma\\) matrix converges to Identity matrix, but we might conclude that, together with \\(\\sigma^2\\), we have reasonable estimated level of the variance matrix of the SVAR model.\n\n\n\n\n\nFigure 7: Gibbs Sampler draws of A and Sigma-SV model"
  },
  {
    "objectID": "index.html#inverted-gamma-2-scale-mixture-of-normal",
    "href": "index.html#inverted-gamma-2-scale-mixture-of-normal",
    "title": "Fiscal Policy Shocks, Aggregate Economy and Stock Prices: Evidence from the Australian Economy",
    "section": "Inverted Gamma 2 Scale Mixture of Normal",
    "text": "Inverted Gamma 2 Scale Mixture of Normal\nCompared to the baseline model,instead of setting \\(\\kappa_1\\) and \\(\\kappa_2\\) as fixed values, the overall shrinkage level for auto-regressive slopes \\(\\kappa_1\\) is assumed to follow an inverse gamma 2 distribution \\(IG2(\\underline{S}_{\\kappa},\\underline{\\nu}_{\\kappa})\\), and shrinkage of constant term \\(\\kappa_2\\) can be set as \\(100 \\times \\kappa_1\\).\nUnder this setting, we consider the following posterior distributions: \\[\\begin{gather}\np(\\kappa|A,\\Sigma,Y,X) \\\\\n\\\\ p(A,\\Sigma|X,Y,\\kappa)\n\\end{gather}\\]\nThe full conditional posterior of \\((A,\\Sigma)\\) is: \\[\\begin{gather}\np(A,\\Sigma|X,Y,\\kappa) \\propto L(A,\\Sigma|Y,X) \\times p(A|\\Sigma,\\kappa) \\times p(\\Sigma) \\\\\n\\\\ \\propto det(\\Sigma)^{-\\frac{K}{2}} exp \\left\\{-\\frac{1}{2}tr \\left[ \\Sigma^{-1}(Y-XA)^{'}(Y-XA)\\right] \\right\\} \\\\\n\\\\ \\times exp \\left\\{ -\\frac{1}{2} tr \\left[ \\Sigma^{-1}(A-\\underline{A})^{'}(\\kappa \\underline{V})^{-1}(A-\\underline{A}) \\right] \\right\\} \\\\\n\\\\ \\times det(\\Sigma)^{\\frac{\\underline{\\nu}+N+1}{2}} exp\\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}\\underline{S} \\right] \\right\\}\n\\end{gather}\\]\nWe recognize kernel of matrix-normal inverse Wharst distribution, with parameters as follows: \\[\\begin{gather}\n\\bar{V} = (X'X+(\\kappa \\underline{V}))^{-1} \\\\\n\\\\ \\bar{A} = \\bar{V}(X'Y+(\\kappa \\underline{V}^{-1}\\underline{A})) \\\\ \\\\ \\bar{S} = \\underline{S}+Y'Y+\\underline{A}^{'}(\\kappa \\underline{V})^{-1}\\underline{A} - \\bar{A}^{'} \\bar{V}^{-1}\\bar{A} \\\\\n\\\\ \\bar{\\nu} = T + \\underline{\\nu}\n\\end{gather}\\]\nThe full-conditional posterior of \\(\\kappa\\) is: \\[\\begin{gather}\np(\\kappa | A,\\Sigma, Y,X) \\propto L(Y|X,A,\\Sigma) \\times p(\\kappa) \\times p(A|\\Sigma,\\kappa) \\times p(\\Sigma) \\\\\n\\\\ \\propto p(\\kappa) \\times p(A|\\Sigma,\\kappa) \\\\\n\\\\ \\propto (\\kappa)^{-\\frac{\\underline{\\nu}_{\\kappa}+2}{2}}\nexp\\left\\{ -\\frac{1}{2} \\frac{\\underline{S}_{\\kappa}}{\\kappa} \\right\\}  \\times exp\\left\\{-\\frac{1}{2}tr\\left[\\Sigma^{-1}(A-\\underline{A})^{'} \\frac{1}{\\kappa}(\\underline{V})^{-1} (A-\\underline{A})\\right]\\right\\} \\times det(\\kappa \\underline{V})^{-\\frac{N}{2}} \\\\\n\\\\ \\propto (\\kappa)^{-\\frac{\\underline{\\nu}_{\\kappa}+2+NK}{2}} exp \\left\\{-\\frac{1}{2} \\frac{1}{\\kappa} \\left[\\underline{S}_{\\kappa} + tr \\left[\\Sigma^{-1}(A-\\underline{A})^{'}\\underline{V}^{-1}(A-\\underline{A}) \\right]\\right] \\right\\}\n\\end{gather}\\]\nwhich we recognise the kernel of inverse gamma 2 distribution with \\[\\begin{gather}\n\\bar{S}_{\\kappa} = \\underline{S}_{\\kappa}+tr \\left[ \\Sigma^{-1} (A-\\underline{A})^{'} \\underline{V}^{-1} (A-\\underline{A})\\right] \\\\\n\\\\ \\bar{\\nu}_{\\kappa} = \\underline{\\nu}_{\\kappa}+NK\n\\end{gather}\\]\nGibbs Sampler can be conducted to get the posterior draws of the extended model, for which we can,\nInitialize \\(\\kappa\\) at \\(\\kappa^{(0)}\\).\nAt each iteration s:\n\nDraw \\((A,\\Sigma)^{(s)} \\sim p(A,\\Sigma| X,Y,\\kappa^{(s-1)})\\)\nDraw \\(\\kappa^{(s)} \\sim p(\\kappa|Y,X,A,\\Sigma)\\)\n\nRepeat 1 and 2 for \\((S_1 + S_2)\\) times.\nDiscard the first \\(S_1\\).\n\nDrawPosterior.e <- function (Y,X,prior.parameters,nu.kappa,S.kappa,S1,S2){\n  \n  N = ncol(Y)\n  K = ncol(X)\n  T = nrow(Y)\n  \n  A.prior <- prior.parameters$A.prior\n  V.prior <- prior.parameters$V.prior\n  S.prior <- prior.parameters$S.prior\n  nu.prior <- prior.parameters$nu.prior\n  \n  kappa           <- c()\n  A.posterior     <- array(NA,c(K,N,(S1+S2)))\n  Sigma.posterior <- array(NA,c(N,N,(S1+S2))) \n  B.posterior     <- array(NA,c(N,N,(S1+S2)))\n  B1.tilde.s      <- array(NA,c(N,K,(S1+S2)))\n  \n  # Initialize kappa.0 \n  kappa[1] <- 1 \n  \n  nu.bar <- nu.prior + T \n  nu.kappa.bar <- nu.kappa + N*K # N*K \n \n  for (s in 1:(S1+S2)){\n    # STEP 1: draw (A Sigma).s from MNIW(A.bar,V.bar,S.bar,nu.bar)\n    V.bar.inv <- t(X)%*%X + solve(kappa[s]*V.prior)\n    V.bar     <- solve(V.bar.inv)\n    \n    A.bar     <- V.bar%*%(t(X)%*%Y + diag(1/diag(kappa[s]*V.prior))%*%A.prior)\n    S.bar     <- S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(kappa[s]*V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar\n              \n    draw.sigma.inv = solve(rWishart(1, df=nu.bar, Sigma=solve(S.bar))[,,1])\n    Sigma.posterior[,,s] = draw.sigma.inv\n    \n    cholSigma.s            = chol(Sigma.posterior[,,s])\n    A.posterior[,,s]       = matrix(MASS::mvrnorm(1,as.vector(A.bar),Sigma.posterior[,,s]%x%V.bar),ncol=N)      \n    \n    L                <- t(chol(V.bar))\n    # B.posterior[,,s] <- t(chol(Sigma.posterior[,,s]))\n    B.posterior[,,s] <- solve(t(chol(Sigma.posterior[,,s])))   ############################\n    B1.tilde.s[,,s]  <- B.posterior[,,s]%*%t(A.posterior[,,s])\n    \n    # STEP 2: draw kappa.s from IG2(S.bar, nu.bar)\n    S.kappa.bar <- S.kappa + sum(diag( draw.sigma.inv %*% t(A.posterior[,,s]-A.prior)%*% diag(1/diag(V.prior)) %*% (A.posterior[,,s]-A.prior)))\n    kappa[s+1]  <- S.kappa.bar / rchisq(1, df=nu.kappa.bar)\n  }   \n  \n  return(list(Sigma.posterior.e = Sigma.posterior[,,(S1+1):(S1+S2)],\n              A.posterior.e = A.posterior[,,(S1+1):(S1+S2)],\n              B1.tilde.s.e = B1.tilde.s[,,(S1+1):(S1+S2)],\n              B.posterior.e = B.posterior[,,(S1+1):(S1+S2)],\n              kappa.e = kappa[(S1+1):(S1+S2)]))\n}\n\nThe sign restrictions would be implied in the same way as the basic model.\nThen we can use the same data to check whether the extension model is working.\n\n\n\n\n\n\nFigure 8 plots the S2 draws of Gibbs Sampler, and it shown to be stationary for A and \\(\\Sigma\\). And it can be observed that the diagonal elements of \\(\\Sigma\\) matrix and sub-diagonal elements of \\(A\\) converges to 1, which is supported by Table 7 and Table 8.\n\n\n\n\n\nFigure 8: Gibbs Sampler draws of A and Sigma\n\n\n\n\nFigure 9 shows the distribution of Gibbs Sampler draws of \\(\\kappa\\), which is right skewed and strictly positive, which make it appropriate to parameterize variance parameters.\n\n\n\n\n\nFigure 9: Gibbs Sampler draws of kappa\n\n\n\n\n\n\n\n\n\n\nTable 7 and Table 8 also shows desired results, suggesting the extended model is producing estimates close to true parameters of the data generating process.\n\n\n\n\nTable 7: Inverted Gamma 2 scale Model - A\n\n\n0.0242\n0.0577\n\n\n0.9840\n0.0021\n\n\n-0.0031\n1.0572\n\n\n\n\n\n\n\n\n\n\nTable 8: Inverted Gamma 2 scale Model - Sigma\n\n\n1.0237\n-0.0001\n\n\n-0.0001\n1.0239"
  },
  {
    "objectID": "index.html#baseline-model-1",
    "href": "index.html#baseline-model-1",
    "title": "Fiscal Policy Shocks, Aggregate Economy and Stock Prices: Evidence from the Australian Economy",
    "section": "Baseline Model",
    "text": "Baseline Model\n\n\n\nTable 9 presented the mean of posterior draws of A matrices as in the reduced form.\n\n\n\n\nTable 9: Inverted Gamma 2 scale Model - A\n\n\nGDP\nSpending\nTaxation\nDebt\nInflation\nInterest\nStock\n\n\n\n\n0.0369\n-0.0219\n0.0774\n0.7148\n3.4125\n2.6006\n-1.0565\n\n\n0.9951\n0.0031\n0.0009\n0.0143\n-0.3256\n-0.0974\n0.0731\n\n\n0.0043\n0.9899\n0.0079\n-0.0205\n0.1128\n-0.1958\n0.0940\n\n\n-0.0041\n0.0052\n0.9656\n-0.0931\n0.0054\n-0.0316\n0.0731\n\n\n0.0004\n0.0007\n0.0026\n1.0079\n-0.1508\n-0.1031\n-0.0178\n\n\n-0.0021\n-0.0018\n0.0001\n-0.0124\n0.0901\n0.2098\n-0.0456\n\n\n0.0007\n-0.0056\n-0.0013\n-0.0172\n0.3296\n1.1204\n-0.0707\n\n\n0.0017\n0.0012\n0.0073\n-0.0223\n0.1229\n0.2384\n0.9554\n\n\n-0.0009\n0.0009\n0.0017\n0.0064\n-0.0694\n-0.0128\n0.0174\n\n\n0.0006\n-0.0009\n-0.0002\n-0.0065\n0.0349\n-0.0411\n0.0256\n\n\n-0.0005\n0.0017\n0.0005\n-0.0190\n-0.0747\n-0.0246\n0.0016\n\n\n0.0004\n0.0004\n0.0003\n-0.0176\n-0.0062\n0.0061\n-0.0436\n\n\n-0.0013\n-0.0019\n-0.0003\n-0.0154\n-0.0021\n0.0040\n-0.0570\n\n\n-0.0007\n0.0066\n-0.0045\n0.0058\n-0.1825\n-0.1645\n0.0809\n\n\n-0.0031\n0.0009\n-0.0118\n0.0272\n-0.0625\n-0.1264\n-0.0138\n\n\n-0.0002\n0.0005\n0.0006\n0.0029\n-0.0262\n-0.0132\n0.0129\n\n\n0.0004\n-0.0002\n0.0010\n-0.0020\n0.0024\n-0.0172\n0.0125\n\n\n0.0001\n0.0004\n0.0007\n-0.0095\n-0.0012\n-0.0266\n0.0161\n\n\n-0.0006\n0.0004\n-0.0001\n-0.0132\n0.0013\n-0.0045\n-0.0045\n\n\n-0.0007\n0.0043\n-0.0028\n0.0027\n0.0263\n0.0444\n-0.0174\n\n\n0.0004\n-0.0025\n0.0087\n0.0090\n-0.1158\n-0.1151\n-0.0445\n\n\n-0.0004\n-0.0018\n-0.0023\n0.0122\n0.0812\n-0.0415\n0.0292\n\n\n0.0000\n0.0002\n0.0003\n0.0015\n-0.0193\n-0.0110\n0.0046\n\n\n0.0002\n0.0000\n0.0004\n-0.0010\n-0.0003\n-0.0116\n0.0099\n\n\n-0.0001\n0.0000\n-0.0005\n-0.0036\n-0.0118\n-0.0216\n0.0094\n\n\n-0.0003\n0.0008\n0.0002\n-0.0102\n0.0288\n0.0139\n0.0066\n\n\n-0.0004\n0.0009\n-0.0005\n0.0055\n0.1163\n0.0260\n-0.0053\n\n\n-0.0012\n0.0012\n-0.0062\n-0.0007\n-0.0397\n0.0129\n0.0206\n\n\n0.0004\n-0.0010\n0.0030\n0.0032\n-0.0783\n-0.1429\n0.0061\n\n\n\n\n\n\nFigure 10 plots the S2 draws of Gibbs Sampler of the baseline model, and it shown to be stationary for A and \\(\\Sigma\\).\n\n\n\n\n\nFigure 10: Posterior draws of A and Sigma-Baseline model\n\n\n\n\n\n\n\nFigure 11 shows the Impulse Response Function of the baseline model for 50,000 draws, from which we can’t observe any significant or meaningful effects on variables of interest.\n\n\n\n\n\nFigure 11: Impulse Response Function-Basic Model"
  },
  {
    "objectID": "index.html#stochastic-volatility-heteroskedasticity-1",
    "href": "index.html#stochastic-volatility-heteroskedasticity-1",
    "title": "Fiscal Policy Shocks, Aggregate Economy and Stock Prices: Evidence from the Australian Economy",
    "section": "Stochastic Volatility Heteroskedasticity",
    "text": "Stochastic Volatility Heteroskedasticity\n\n\n\nAs presented in Figure 12, the stochastic volatility mean plot has a significant difference with Figure 13, it exhibits higher volatility during AfC, GFC and Covid-19 pandemic.\n\n\n\n\n\nFigure 12: Time Series Plot of Stochastic Volatility Mean\n\n\n\n\nFigure 13 plots the S2 draws of Gibbs Sampler of the baseline model, and it shown to be stationary for A and \\(\\Sigma\\).\n\n\n\n\n\nFigure 13: Posterior draws of A and Sigma-Baseline model\n\n\n\n\n\n\n\nFigure 14 presents the Impulse Response Function of the Stochastic Volatility model, which suggest a slight decrease in GDP while government spending rises, decrease in inflation and Cash Rate Target and Total Taxes. From this plot, we can see that responses are estimated with more confidence, shown by narrower confidence intervals.\n\n\n\n\n\nFigure 14: Impulse Response Function-SV model"
  },
  {
    "objectID": "index.html#inverted-gamma-2-scale-mixture-of-normal-1",
    "href": "index.html#inverted-gamma-2-scale-mixture-of-normal-1",
    "title": "Fiscal Policy Shocks, Aggregate Economy and Stock Prices: Evidence from the Australian Economy",
    "section": "Inverted Gamma 2 Scale Mixture of Normal",
    "text": "Inverted Gamma 2 Scale Mixture of Normal\n\n\n\nFigure 15 shows the distribution of Gibbs Sampler draws of \\(\\kappa\\).\n\n\n\n\n\nFigure 15: Empirical Gibbs Sampler draws of kappa\n\n\n\n\nFigure 16 plots the S2 draws of Gibbs Sampler of the inverted gamma 2 scale mixture, and it shown to be stationary for A and \\(\\Sigma\\).\n\n\n\n\n\nFigure 16: Posterior draws of A and Sigma-Inverted Gamma 2 Scale Mixture\n\n\n\n\n\n\n\nFigure 17 presents the Impulse Response Function of the extended model, which suggest a slight decrease in GDP while government spending rises, decreases in GDP and Cash Rate Target, with increase in stock prices. Compared to the baseline model, the change is not much pronounced, but we can observe a wider confidence interval on Inflation.\n\n\n\n\n\nFigure 17: Impulse Response Function-Extended model"
  }
]